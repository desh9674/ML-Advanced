{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageClassification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2TazYrBStewP","colab_type":"text"},"source":["#CIFAR-10 Dataset Description\n","CIFAR-10 Dataset Description\n","Image Source : here\n","\n","CIFAR-10 is a widely used dataset for Machine Learning research, which is created by A. Krizhevsky et al.\n","\n","It consists of 60,000 - 32x32 color images in 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck) with 50,000 training images and 10,000 testing images.\n","\n","Each class has 6,000 images. The classes in a CIFAR-10 dataset are mutually exclusive.\n","\n","At a glance:\n","\n","Number of classes: 10\n","Size of image: 32 x 32 x 3\n","Note: In this course, we use only a subset of the above dataset due to memory constraints in online cloud platform. We will be explaining the generation of subset in the upcoming cards\n","\n","![alt text](https://docs-cdn.fresco.me/system/attachments/files/000/223/478/large/705ec5e1e9e4956563c19f0aca33fdc39e269a48/cifar_10_1.jpeg)\n","\n","\n","https://www.cs.toronto.edu/~kriz/cifar.html\n","\n","sample dataset for below code\n","http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz>cifar-10-python.tar.gz\n","\n","```\n","\n","#Data Loading\n","import os\n","import numpy as np\n","def _load_cifar10_batch(file): \n","    import cPickle \n","    fo = open(file, 'rb') \n","    dict = cPickle.load(fo) \n","    fo.close() \n","    return dict['data'].reshape(-1, 32, 32, 3), dict['labels'] # reshaping the data to 32 x 32 x 3  \n","print('Loading...') \n","batch_fns = [os.path.join(\"./\", 'cifar-10-batches-py', 'data_batch_' + str(i)) for i in range(1, 6)] \n","data_batches = [_load_cifar10_batch(fn) for fn in batch_fns] \n","\n","\n","#Data Stacking\n","data_all = np.vstack([data_batches[i][0] for i in range(len(data_batches))]).astype('float') \n","labels_all = np.vstack([data_batches[i][1] for i in range(len(data_batches))]).flatten() \n","\n","\"\"\"\n","Subset Generation\n","As explained in dataset description, we use only a subset of CIFAR-10 dataset.\n","\n","The dataset with 50,000 samples is split in the ratio 92:8. This split is done to take a smaller portion of 50000 samples (i.e the 8% contains only 4000 images).\n","\n","These 4000 samples are used for generating the train and test sets for classification.\n","\n","Here, StratifiedShuffleSplit is used to split the dataset. It splits the data by taking equal number of samples from each class in a random manner.\n","\n","\"\"\"\n","#Splitting the whole training set into 92:8\n","seed=7\n","from sklearn.cross_validation import StratifiedShuffleSplit\n","data_split = StratifiedShuffleSplit(labels_all,1, test_size=0.08,random_state=seed) #creating data_split object with 8% test size \n","for train_index, test_index in data_split:\n","    split_data_92, split_data_8 = data_all[train_index], data_all[test_index]        \n","    split_label_92, split_label_8 = labels_all[train_index], labels_all[test_index]\n","\n","\n"," 4000 samples are split in the ratio 7:3. (i.e., 2800 for training and 1200 for testing) using StratifiedShuffleSplit.\n","    \n","#Splitting the training set into 70 and 30\n","train_test_split = StratifiedShuffleSplit(split_label_8,1, test_size=0.3,random_state=seed) #test_size=0.3 denotes that 30 % of the dataset is used for testing.\n","for train_index, test_index in train_test_split:\n","    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]     \n","    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n","train_data = train_data_70 #assigning to variable train_data\n","train_labels = train_label_70 #assigning to variable train_labels\n","test_data = test_data_30\n","test_labels = test_label_30    "]},{"cell_type":"markdown","metadata":{"id":"-i-a0kBUK0wH","colab_type":"text"},"source":["#Need for Preprocessing\n","Using the Data preprocessing step, the raw data is converted into a form suitable for subsequent analysis. All the steps before data training (model creation) can be considered as a pre-processing step.\n","\n","The quality of an image is greatly influenced by its clarity and the device used to capture it.\n","\n","The captured image may contain noise and irregularities, which can be removed via preprocessing steps.\n","\n","Some of the common preprocessing techniques include:\n","\n","Normalization\n","\n","Dimensionality reduction (eg. PCA, SVD)\n","\n","Feature Extraction (e.g. SIFT, HOG)\n","\n","Whitening\n","\n","Denoising\n","\n","Contrast Stretching\n","\n","Background subtraction\n","\n","Image Enhancement\n","\n","Smoothing\n","\n","In the following cards, we will describe some of the preprocessing techniques that can be applied to images.\n","\n","#Normalization\n","Normalization is the process of converting the pixel intensity values to a normal state.\n","\n","It follows a normal distribution.\n","\n","A normalized image has mean = 0 and variance = 1\n","```\n","# definition of normalization function\n","def normalize(data, eps=1e-8): \n","    data -= data.mean(axis=(1, 2, 3), keepdims=True) \n","    std = np.sqrt(data.var(axis=(1, 2, 3), ddof=1, keepdims=True)) # calculating standard deviation\n","    std[std < eps] = 1. \n","    data /= std \n","    return data \n","# calling the function\n","train_data = normalize(train_data) \n","test_data = normalize(test_data) \n","# prints the shape of train data and test data \n","print 'train_data: ', train_data.shape\n","print 'test_data: ', test_data.shape\n","\n","```\n","\n","ZCA Whitening\n","Normalization is followed by a ZCA whitening process.\n","\n","The main aim of whitening is to reduce data redundancy, which means the features are less correlated and have the same variance.\n","\n","ZCA stands for zero-phase component analysis. ZCA whitened images resemble the normal image.\n","```\n","# Computing whitening matrix \n","train_data_flat = train_data.reshape(train_data.shape[0], -1).T\n","test_data_flat = test_data.reshape(test_data.shape[0], -1).T\n","print('train_data_flat: ', train_data_flat.shape)\n","print('test_data_flat: ', test_data_flat.shape)\n","train_data_flat_t = train_data_flat.T\n","test_data_flat_t = test_data_flat.T\n","```\n","\n","Principle Component Analysis (PCA)\n","Principle Component Analysis (PCA)\n","The major function of PCA is to decompose a multivariate dataset into a set of successive orthogonal components. These orthogonal components explain a maximum amount of the variance.\n","\n","PCA is a dimensionality reduction technique.\n","\n","The whitened data is given as the input to PCA.\n","```\n","from sklearn.decomposition import PCA\n","# n_components specify the no.of components to keep\n","train_data_pca = PCA(n_components=train_data_flat.shape[1]).fit_transform(train_data_flat)\n","test_data_pca = PCA(n_components=test_data_flat.shape[1]).fit_transform(test_data_flat)\n","train_data_pca = train_data_pca.T\n","test_data_pca = test_data_pca.T\n","```\n","![alt text](https://docs-cdn.fresco.me/system/attachments/files/000/215/796/large/ae904f45bdf68a7805c76c8a430a2b6dd72a633b/PCA.jpeg)\n","\n","\n","#Singular Value Decomposition (SVD)\n","Singular Value Decomposition (SVD)\n","SVD is a dimensionality reduction technique that has been used in several fields such as image compression, face recognition, and noise filtering.\n","\n","In this method, a digital image (generally considered as a matrix) is decomposed into three other matrices.\n","\n","The singular values (less in number) obtained from this refactoring process can preserve useful features of the original image without utilizing high storage space in the memory.\n","\n","For further details, click here.![alt text](https://docs-cdn.fresco.me/system/attachments/files/000/215/914/large/9fa5e9b578e75cd27f3cdc7be171d7e2139da7d6/Singular_Value_Decomposition_SVD.jpeg)\n","\n","\n","\n","#Singular Value Decomposition (SVD)\n","The below code for SVD may not work in the available online cloud playground due to package issues. So, it is better to try this out in a local Python environment.\n","```\n","from skimage import color\n","# definition for SVD\n","def svdFeatures(input_data):\n","    svdArray_input_data=[]\n","    size = input_data.shape[0]\n","    for i in range (0,size):\n","        img=color.rgb2gray(input_data[i])\n","        U, s, V = np.linalg.svd(img, full_matrices=False);\n","        S=[s[i] for i in range(30)]\n","        svdArray_input_data.append(S)\n","        svdMatrix_input_data=np.matrix(svdArray_input_data)\n","    return svdMatrix_input_data\n","# apply SVD for train and test data\n","train_data_svd=svdFeatures(train_data)\n","test_data_svd=svdFeatures(test_data)\n","```\n","\n","\n","#Scale-Invariant Feature Transform for Feature Generation (SIFT)\n","SIFT is mainly used for images that are less simple and less organized.\n","\n","Even the photographs of the same material will undergo scale change corresponding to the distance from the material, focal length etc. This is one of the reasons for not considering the raw pixel values as useful features for images.\n","\n","The main aim of using SIFT for feature extraction is to obtain features that are not sensitive to changes in scale, rotation, image resolution, illumination, etc.\n","\n","The major steps involved in SIFT algorithm are:\n","\n","Scale-space Extrema Detection\n","\n","Keypoint Localization\n","\n","Orientation Assignment\n","\n","Keypoint Descriptor\n","\n","For further details, refer here."]},{"cell_type":"markdown","metadata":{"id":"MAo767mEPJGY","colab_type":"text"},"source":["#Convolutional Neural Networks (CNN)\n","Deep learning has become more important for learning complex algorithms. It is a more refined form of machine learning, which is based on neural networks that emulate the brain.\n","\n","Neural network consists of:\n","\n","input layer\n","\n","hidden layers\n","\n","output layer\n","\n","Each layer is composed of nodes, where the computation happens.\n","\n","Neural Network consists of interconnected neurons that passes\n","\n","messages between each other.\n","\n","CNN is a special case of neural networks that consists of multiple convolutional layers, pooling layers and finally, fully connected layers.\n","\n","The improved network structure helps in saving memory and computational complexity. They are mainly used in pattern and image recognition problems.\n","\n","5 of 5\n","\n","#Testing\n","Cross validation is considered as a model validation technique to evaluate the performance of a model on unseen data.\n","\n","It is a better estimate to evaluate testing accuracy than training accuracy on unseen data.\n","\n","Points to remember:\n","\n","Cross validation gives high variance if the testing set and training set are not drawn from the same population.\n","\n","Allowing training data to be included in testing data will not give actual performance results.\n","\n","In cross validation, the number of samples used for training the model is reduced, and the results depend upon the choice of the pair of training and testing sets.\n","\n","You can refer to the various cross validation approaches from here.\n","\n","Partitioning the Data\n","It is a methodological mistake to test and train on the same dataset because the classifier would fail to predict correctly for any unseen data. This could result in overfitting.\n","\n","To avoid this problem,\n","\n","The data is split into train set, validation set, and test set.\n","\n","Training Set: The data used to train the classifier.\n","\n","Validation Set: The data used to tune the classifier model parameters i.e., to understand how well the model has been trained (as part of training data).\n","\n","Testing Set: The data used to evaluate the performance of the classifier (unseen data by the classifier).\n","\n","This will help us to know the efficiency of our model.\n","\n","Since the online platform used in this course doesn't support huge dataset, only a few samples are taken for training and testing.\n","\n","\n","```\n","lassification accuracy is defined as the percentage of correct predictions.\n","\n","To calculate class wise accuracy,\n","\n","         CA = (correctly predicted images of a class/(Total images of the class)) * 100\n","\n","\n","\n","#To see the accuracy of each class. \n","\n","accuracy=[]\n","\n","leng = len(conf_matrix) #finding the length of confusion matrix\n","\n","for i in range(leng): \n","\n","\n","\n","#each diagonal element (conf_matrix[i,i]) is divided by the sum of the \n","\n","elements of that particular row (conf_matrix[i].sum()).\n","\n","\n","\n","    ac=(conf_matrix[i,i]/((conf_matrix[i].sum())+.0000001))*100 \n","\n","    accuracy.append(ac)\n","\n","print accuracy\n","\n","Overall accuracy is given by, OA = Sum of class-wise accuracy/no of classes\n","\n","The code is as follows:\n","\n","\n","summation=0\n","\n","no_of_classes = 10\n","\n","for i in range(0,len(accuracy)):\n","\n","    summation+=accuracy[i]\n","\n","overall_accuracy = summation/no_of_classes\n","\n","print overall_accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"WDT3ocRjRtaZ","colab_type":"text"},"source":["#TASK KERAS"]},{"cell_type":"code","metadata":{"id":"NNvOq0fqs9QI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"d140c6f2-9239-4475-d091-472a4889f573","executionInfo":{"status":"ok","timestamp":1570704611632,"user_tz":-330,"elapsed":8981,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","import numpy as np\n","\n","# load dataset\n","(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n","# load train and test dataset\n","def load_dataset():\n","    # load dataset\n","    (trainX, trainy), (testX, testY) = fashion_mnist.load_data()\n","    # reshape dataset to have a single channel\n","    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n","    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n","    # one hot encode target values\n","    trainy = to_categorical(trainy)\n","    testY = to_categorical(testY)\n","    return trainX, trainy, testX, testY"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 3us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 2s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gbNO4DxCSfbP","colab_type":"code","colab":{}},"source":["seed=9\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","data_split = StratifiedShuffleSplit(test_size=0.08, random_state=seed)\n","for train_index, test_index in data_split.split(trainX, trainy):\n","\n","    split_data_92, split_data_8 = trainX[train_index], trainX[test_index]\n","\n","    split_label_92, split_label_8 = trainy[train_index], trainy[test_index]\n","train_test_split = StratifiedShuffleSplit(test_size=0.3, random_state=seed) #test_size=0.3 denotes that 30 % of the dataset is used for testing.\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"331d7M70S9_u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c42d6530-5e7d-497c-ee8f-5537b0e3592b","executionInfo":{"status":"ok","timestamp":1570706020644,"user_tz":-330,"elapsed":913,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["for train_index, test_index in train_test_split.split(split_data_8,split_label_8):\n","\n","    train_data_70, test_data_30 = split_data_8[train_index], split_data_8[test_index]\n","\n","    train_label_70, test_label_30 = split_label_8[train_index], split_label_8[test_index]\n","train_data = train_data_70 #assigning to variable train_data\n","\n","train_labels = train_label_70 #assigning to variable train_labels\n","\n","test_data = test_data_30\n","\n","test_labels = test_label_30\n","print('train_data : ',     train_data)\n","\n","print('train_labels : ',   train_labels)\n","\n","print('test_data : ',      test_data)\n","\n","print('test_labels : ',    test_labels)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["train_data :  [[[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 1 0 0]\n","  ...\n","  [0 0 0 ... 5 0 0]\n","  [0 0 0 ... 6 0 0]\n","  [0 0 0 ... 1 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," ...\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]]\n","train_labels :  [0 1 6 ... 3 1 1]\n","test_data :  [[[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," ...\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]\n","\n"," [[0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  ...\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]\n","  [0 0 0 ... 0 0 0]]]\n","test_labels :  [0 5 7 ... 3 2 9]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j35mMxEWYAZd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ee110014-13eb-421a-a90e-a8fed3419085","executionInfo":{"status":"ok","timestamp":1570706035147,"user_tz":-330,"elapsed":967,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["# definition of normalization function\n","\n","def normalize(data, eps=1e-8):\n","\n","    data -= data.mean(axis=(0, 1, 2), keepdims=True) \n","\n","    std = np.sqrt(data.var(axis=(0, 1, 2), ddof=1, keepdims=True)) # calculating standard deviation\n","\n","    std[std < eps] = 1.\n","\n","    data /= std\n","\n","    return data\n","train_data=train_data.astype('float64')\n","test_data=test_data.astype('float64')\n","# calling the function\n","\n","train_data = normalize(train_data)\n","\n","test_data = normalize(test_data)\n","# prints the shape of train data and test data\n","\n","print('train_data: ', train_data          )\n","\n","print('test_data: ',  test_data         )"],"execution_count":6,"outputs":[{"output_type":"stream","text":["train_data:  [[[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.79589088 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.7514801  -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.74037741 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.79589088 -0.80699357\n","   -0.80699357]]\n","\n"," [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]]\n","\n"," [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]]\n","\n"," ...\n","\n"," [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]]\n","\n"," [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]]\n","\n"," [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  ...\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]\n","  [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","   -0.80699357]]]\n","test_data:  [[[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]\n","\n"," [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]\n","\n"," [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]\n","\n"," ...\n","\n"," [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]\n","\n"," [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]\n","\n"," [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  ...\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]\n","  [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","   -0.81083669]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FnaYZOxDWt_o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"70102fa7-d0a7-4b17-a454-fb71729c459e","executionInfo":{"status":"ok","timestamp":1570706054470,"user_tz":-330,"elapsed":903,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["# Computing whitening matrix \n","\n","train_data_flat = train_data.reshape(train_data.shape[0], -1).T\n","\n","test_data_flat = test_data.reshape(test_data.shape[0], -1).T\n","\n","print('train_data_flat: ',  train_data_flat        )\n","\n","print('test_data_flat: ',     test_data_flat          )\n","\n","\n","\n","train_data_flat_t = train_data_flat.T\n","\n","test_data_flat_t = test_data_flat.T\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["train_data_flat:  [[-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]\n"," [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]\n"," [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]\n"," ...\n"," [-0.79589088 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]\n"," [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]\n"," [-0.80699357 -0.80699357 -0.80699357 ... -0.80699357 -0.80699357\n","  -0.80699357]]\n","test_data_flat:  [[-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]\n"," [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]\n"," [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]\n"," ...\n"," [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]\n"," [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]\n"," [-0.81083669 -0.81083669 -0.81083669 ... -0.81083669 -0.81083669\n","  -0.81083669]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7CFkwsRhWvaI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"74276aa1-08c5-43b2-94de-fcb7dc5eac7c","executionInfo":{"status":"ok","timestamp":1570706067822,"user_tz":-330,"elapsed":1206,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["from sklearn.decomposition import PCA\n","\n","# n_components specify the no.of components to keep\n","\n","train_data_pca = PCA(n_components=train_data.shape[1]).fit_transform(train_data_flat)\n","\n","test_data_pca =PCA(n_components=test_data.shape[1]).fit_transform(test_data_flat)\n","\n","print( train_data_pca                )\n","\n","print( test_data_pca             ) \n","\n","train_data_pca = train_data_pca.T\n","\n","test_data_pca = test_data_pca.T"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[-48.8353608  -10.09929446  -5.68424705 ...   0.16228964   0.2467461\n","    0.72782834]\n"," [-48.83400607 -10.09922325  -5.68301089 ...   0.16147601   0.24772916\n","    0.72671348]\n"," [-48.81999397 -10.10285095  -5.6753278  ...   0.16142327   0.2621737\n","    0.72885717]\n"," ...\n"," [-47.54340165  -9.42846415  -4.6915174  ...   0.23164538   1.07587441\n","    0.50553854]\n"," [-48.57670043  -9.86242271  -5.60291988 ...   0.05444069   0.45313798\n","    0.66871658]\n"," [-48.81420729 -10.07988015  -5.69104811 ...   0.12613004   0.25425758\n","    0.71167824]]\n","[[-32.31296431  -6.2126007   -3.36998485 ...   0.38448069   0.24667314\n","    0.65584848]\n"," [-32.31296431  -6.2126007   -3.36998485 ...   0.38448069   0.24667314\n","    0.65584848]\n"," [-32.3010017   -6.21872634  -3.36594828 ...   0.38422524   0.24350656\n","    0.66066067]\n"," ...\n"," [-31.57566912  -5.88950443  -2.9665535  ...   0.78878668   0.33532483\n","    0.26736214]\n"," [-32.08537108  -6.04989022  -3.37871062 ...   0.42926997   0.19569179\n","    0.34402801]\n"," [-32.28224143  -6.197356    -3.37643764 ...   0.36181081   0.21592903\n","    0.60451164]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gGfx1RR9YIxl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"59addf4f-674b-48bb-eec1-970b02760adf","executionInfo":{"status":"ok","timestamp":1570706097630,"user_tz":-330,"elapsed":18143,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["from skimage import color\n","def svdFeatures(input_data):\n","\n","    svdArray_input_data=[]\n","\n","    size = input_data.shape[0]\n","\n","    for i in range (0,size):\n","\n","        img=color.rgb2gray(input_data[i])\n","\n","        U, s, V = np.linalg.svd(img, full_matrices=False);\n","\n","        S=[s[i] for i in range(28)]\n","\n","        svdArray_input_data.append(S)\n","\n","        svdMatrix_input_data=np.matrix(svdArray_input_data)\n","\n","    return svdMatrix_input_data\n","\n","\n","\n","# apply SVD for train and test data\n","\n","train_data_svd=svdFeatures(train_data)\n","\n","test_data_svd=svdFeatures(test_data)\n","print(train_data_svd.shape)\n","print(test_data_svd.shape) "],"execution_count":10,"outputs":[{"output_type":"stream","text":["(3360, 28)\n","(1440, 28)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sI2-KjkQYL60","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8f21e190-69d8-40be-b49c-0de0523f598b","executionInfo":{"status":"ok","timestamp":1570706134928,"user_tz":-330,"elapsed":35729,"user":{"displayName":"dhairyashil deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBekp9I1RUanWY6fBLVDxE8k-iU14p_q2CyE-K2Kg=s64","userId":"08228054099836219584"}}},"source":["from sklearn import svm #Creating a svm classifier model\n","\n","clf = svm.SVC(gamma=0.001, probability=True) #train_data_flat_tModel training\n","\n","train = clf.fit(train_data_flat_t, train_labels)\n","predicted= clf.predict(test_data_flat_t)\n","\n","score = clf.score(test_data_flat_t, test_labels)\n","print(\"score\",score)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["score 0.8277777777777777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rFibjhJxYQu0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
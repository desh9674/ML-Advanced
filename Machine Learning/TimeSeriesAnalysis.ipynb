{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TimeSeriesAnalysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"D_bWNB9ogn1G","colab_type":"text"},"source":["#What is a Time Series?\n","What is a Time Series?\n","Time Series is a series of observations measured over time.\n","\n","These observations are applicable to different fields such as\n","\n","Cardiology (Heart Rate Monitor)\n","\n","Finance (Stock Market Data)\n","\n","Neurology (EEG Data)\n","\n","Meteriology ( Temperature Measurements)\n","\n","#Time Series Properties\n","Time Series Properties\n","Univariate Data\n","\n","Values are indexed by time\n","\n","Observations captured in constant time intervals\n","#Uniqueness of Time Series\n","The same data is captured over a series of time intervals and the models are also a bit unique to the data.\n","\n","Ideally, when you collect observations, you capture multiple data attributes, so we apply multivariate models in those situations.\n","\n","In this topic, since you collect a single attribute over time, it is unique.\n","\n","#Course Structure\n","In the first part of the course, you will understand how to slice and dice time series data.\n","\n","In the second part, you will understand how to fit models on time series data.\n","\n","You will also learn how to implement the concepts through Python.\n"]},{"cell_type":"markdown","metadata":{"id":"YnBAnoMFg1wa","colab_type":"text"},"source":["#Date as an Index\n","Indexing is the process of sequencing a given set of data points for easy searching and retrieval.\n","\n","Ideally indexing is just numbering or sequencing the data based on a numeric.\n","\n","For time series data, the date-time attribute is the index.\n","\n","Here the data points are studied at different time steps.\n","#Why Use Date as Index?\n","Date as Index has several advantages. It gives you flexibility to aggregate and disintegrate your data based on any time step.\n","\n","You will learn them through Python so that you can practically see how it works.\n","\n","#Date as Index in Python\n","In Python, when you load a time series data, you can specify the index to be the date column.\n","```\n","import pandas as pd \n","date = [pd.Timestamp(\"2017-01-01\"),\n","        pd.Timestamp(\"2017-01-02\"),\n","        pd.Timestamp(\"2017-01-03\")]\n","timeSeries = pd.Series(np.random.randn(len(date)), index=date)\n","In the first step, we create date values. In the second step, we create random time series with date as index.\n","\n","timeSeries.index \n","DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03'], dtype='datetime64[ns]', freq=None)\n","```\n","\n","#Retrieving the Values\n","If you want to pull out the value at a given timestamp, you can easily reference the date to pull the value, since it is a date time index.\n","\n","timeSeries \n","2017-01-01   -1.215527\n","2017-01-02   -0.401494\n","2017-01-03    1.741686\n","For the above code, if you want to get the value for Jan 1, all you have to code is,\n","\n","timeSeries['2017-01-01']\n","-1.2155267083127297\n","This makes the work of the analyst easy.\n","\n","#Retrieving a Range of Dates\n","Once your time series is indexed by date, you can retrieve a single date as well as a date range.\n","\n","You pass the start and the end date to retrieve all values in the given range.\n","\n","timeSeries['2017-01-01':'2017-01-03']\n","2017-01-01   -1.215527\n","2017-01-02   -0.401494\n","2017-01-03    1.741686\n","dtype: float64\n","In the above example, all the values specified in the range are retrieved.\n","\n","#Date Range\n","In time series, sometimes the date values are not provided explicitly. So how will you generate the date time values and index in that scenario?\n","\n","date_range() Function in Python helps in creating a set of sequential date time values in a given range.\n","\n","There are many ways to create a sequence of dates based on the parameters passed to the function.\n","\n","The date_range() function in Python has multiple features and parameters. You have the flexibility to generate date values in many ways. You will learn some of them in the following cards.\n","\n","#Date Range Generate Dates\n","Say you know the start date and the end date, and you would want to generate a set of dates in that range.\n","\n","You can do that using Python in the following way\n","```\n","pd.date_range(start='2017-01-01',end='2017-01-19',freq='B')\n","Output \n","DatetimeIndex(['2017-01-02', '2017-01-03', '2017-01-04', '2017-01-05',\n","               '2017-01-06', '2017-01-09', '2017-01-10', '2017-01-11',\n","               '2017-01-12', '2017-01-13', '2017-01-16', '2017-01-17',\n","               '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","```\n","Here the Start Date was Jan 1 , 2017 and the end date is Jan 19 , 2017. The freq = 'B' signifies business day. Hence you will not find any date that is a saturday or sunday.\n","7 of 11\n","\n","#Generating Dates in Time Intervals\n","In the previous example, you saw how to generate dates in a range for business days.\n","You can go a bit granular and generate based on time steps (Hours, Minutes and Seconds).\n","Say you want to generate dates starting from Jan 1, 2017, 00:00:00 hrs every hour/minute or second you will do that in the following way In the following examples, the parameter freq= controls how the different date values are generated.\n","When freq = 'H':\n","```\n","pd.date_range(start=\"2017-01-01\", periods=3, freq='H')\n","Output\n","\n","DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 01:00:00',\n","               '2017-01-01 02:00:00'],\n","              dtype='datetime64[ns]', freq='H')\n","When freq = 'T':\n","\n","pd.date_range(start=\"2017-01-01\", periods=3, freq='T')`\n","Output\n","\n","DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 00:01:00',\n","               '2017-01-01 00:02:00'],\n","              dtype='datetime64[ns]', freq='T')\n","When freq = 'S':\n","\n","pd.date_range(start=\"2017-01-01\", periods=3, freq='S')\n","Output\n","\n","DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 00:00:01',\n","               '2017-01-01 00:00:02'],\n","              dtype='datetime64[ns]', freq='S')`\n","\n","```\n","You can get the list of other offsets for freq from Offset Aliases\n","\n","#Varying Frequencies\n","So far, you have seen how to generate date time indices at specific frequencies\n","\n","Let's say you want to generate date-time values that are 1 day, 1 hour, 1 minute and 10 seconds apart.\n","\n","How will you do that using Python?\n","\n","See the code below.\n","```\n","import pandas as pd \n","pd.date_range(start=\"2017-01-01\", periods=5, freq='1D1h1min10s')\n","DatetimeIndex(['2017-01-01 00:00:00', '2017-01-02 01:01:10',\n","               '2017-01-03 02:02:20', '2017-01-04 03:03:30',\n","               '2017-01-05 04:04:40'],\n","              dtype='datetime64[ns]', freq='90070S')\n","\n","```\n","You can give what kind of frequency you need by customizing the freq = parameter.\n","\n","#Generating Custom Date Ranges\n","Instead of specifying a date, you can also specify a day from when you want to generate the date time.\n","\n","For example, you want to generate date time stamp every Friday for five instances from a given start date.\n","\n","pd.date_range(start=\"2017-01-01\", periods=5, freq='W-FRI')\n","DatetimeIndex(['2017-01-06', '2017-01-13', '2017-01-20', '2017-01-27',\n","               '2017-02-03'],\n","              dtype='datetime64[ns]', freq='W-FRI')\n","freq= 'W-FRI' here W stands for Week.\n","\n","#Combining Indices\n","You have generated separate indices with different dates and would want to combine them . How would you do that ?\n","The code below explains the steps.\n","```\n","a = pd.date_range(start=\"2017-01-01\", periods=10, freq='BAS-JAN')\n","b = pd.date_range(start=\"2017-01-01\", periods=10, freq='A-FEB')\n","a.union(b)\n","DatetimeIndex(['2017-01-02', '2017-02-28', '2018-01-01', '2018-02-28',\n","               '2019-01-01', '2019-02-28', '2020-01-01', '2020-02-29',\n","               '2021-01-01', '2021-02-28', '2022-01-03', '2022-02-28',\n","               '2023-01-02', '2023-02-28', '2024-01-01', '2024-02-29',\n","               '2025-01-01', '2025-02-28', '2026-01-01', '2026-02-28'],\n","              dtype='datetime64[ns]', freq=None)\n","```\n","First index generated 10 first business days in January starting 2017\n","\n","Second index genetated 10 last buisiness days in February starting 2017.\n","\n","The union() function helped in combining one index to another."]},{"cell_type":"markdown","metadata":{"id":"M7zGt8sNhQLl","colab_type":"text"},"source":["#Resampling Time Series\n","Resampling Time Series\n","You have your time series data captured in a specific time interval (frequency). This could be Hourly, Daily, and Weekly but you are interested in aggregating this date at a different frequency, i.e., Monthly, Yearly, etc. How do you think you can achieve that?\n","\n","Resampling will help you.\n","\n","Resampling is the process of converting your time series data from a given frequency to the desired frequency.\n","\n","Upsampling is converting the data from a low frequency to a high frequency.\n","\n","Downsampling is converting the data from a high frequency to a low frequency.\n","\n","Why Resample?\n","The collected Time Series Data might not always be at uniform intervals. To study them, they have to be confined to regular time intervals.\n","\n","Resampling helps in these situations.\n","\n","#Downsample Scenario\n","Let us take an example where customers are visiting a supermarket.\n","\n","You are interested in studying the customer incidence pattern at different time steps.\n","\n","You can simulate that scenarios in the following way using Python.\n","```\n","import numpy as np\n","import pandas as pd\n","customerArrival = pd.date_range('18/09/2017 8:00', periods=600, freq='T')\n","custArrivalTs = pd.Series(np.random.randint(0, 100, len(customerArrival)), index=customerArrival)\n","custArrivalTs.head(10)\n","2017-09-18 08:00:00    32\n","2017-09-18 08:01:00    32\n","2017-09-18 08:02:00    85\n","2017-09-18 08:03:00    59\n","2017-09-18 08:04:00    53\n","2017-09-18 08:05:00    76\n","2017-09-18 08:06:00    60\n","2017-09-18 08:07:00    83\n","2017-09-18 08:08:00    16\n","2017-09-18 08:09:00    85\n","```\n","The data says that 32 customers have arrived at 8:00 and 76 customers have come at 8:05 . This is just a hypothetical number.\n","\n","#Downsample Data\n","In the previous card, you saw how to create a random customer incidence scenario for every minute.\n","\n","You are not interested in customer incidence every minute but you would want to get the mean customer incidence every 10 mins.\n","\n","You will resample (downsample) your time series in the following way.\n","```\n","custArrivalTs.resample('10min').head()\n","2017-09-18 08:00:00    58.1\n","2017-09-18 08:10:00    46.2\n","2017-09-18 08:20:00    54.5\n","2017-09-18 08:30:00    48.1\n","2017-09-18 08:40:00    40.8\n","```\n","The default aggregation is using the arithmetic mean.\n","\n","#Custom Aggregation\n","If you do not want the aggregation using the mean, you can specify your custom function.\n","\n","See the below code to understand that process.\n","```\n","custArrivalTs.resample('10min', how='sum').head()\n","2017-09-18 08:00:00    581\n","2017-09-18 08:10:00    462\n","2017-09-18 08:20:00    545\n","2017-09-18 08:30:00    481\n","2017-09-18 08:40:00    408\n","Freq: 10T, dtype: int64\n","```\n","\n","#Other Custom Aggregation Options\n","You have seen how to pass custom aggregation functions to downsample a time series data.\n","\n","In this example, you will notice how to get the maximum incidence in a given time interval.\n","\n","```\n","custArrivalTs.resample('1h', how='max').head()\n","2017-09-18 08:00:00    95\n","2017-09-18 09:00:00    99\n","2017-09-18 10:00:00    98\n","2017-09-18 11:00:00    98\n","2017-09-18 12:00:00    98\n","Freq: H, dtype: int64\n","```\n","The above output is the maximum incidence at a given hour.\n","\n","#Using Lambda Function in Custom Aggregation\n","When you perform down sampling and you want to write your own custom function, you can accomplish that in the following manner.\n","\n","```\n","import random\n","custArrivalTs.resample('1h', how=lambda m: random.choice(m)).head()\n","2017-09-18 08:00:00    79\n","2017-09-18 09:00:00    67\n","2017-09-18 10:00:00    83\n","2017-09-18 11:00:00    26\n","2017-09-18 12:00:00    20\n","Freq: H, dtype: int64\n","```\n","\n","#Open High Low Close\n","Let's say you are analyzing customer incidence data. You would wish to see the opening, closing, high and low incidence values in a given interval of time.\n","\n","How will you do that?\n","\n","See the code below.\n","```\n","custArrivalTs.resample('1h', how='ohlc').head()\n"," \t               open \thigh    low \tclose\n","2017-09-18 08:00:00 \t32 \t95 \t1 \t66\n","2017-09-18 09:00:00 \t75 \t99 \t0 \t20\n","2017-09-18 10:00:00 \t16 \t98 \t1 \t6\n","2017-09-18 11:00:00 \t66 \t98 \t3 \t92\n","2017-09-18 12:00:00 \t50 \t98 \t2 \t35\n","```\n","This scenario has a lot of applications in Financial Data Analysis.\n","\n","#Upsampling\n","In upsampling, the frequency of the data points is more than that of the original data captured.\n","\n","For example, you are creating ten time stamps with random values every one hour on a given date.\n","```\n","sampleRng = pd.date_range('9/18/2017 8:00', periods=10, freq='H')\n","sampleTs = pd.Series(np.random.randint(0, 100, len(sampleRng)), index=sampleRng)\n","sampleTs\n","2017-09-18 08:00:00    62\n","2017-09-18 09:00:00    22\n","2017-09-18 10:00:00    22\n","2017-09-18 11:00:00    55\n","2017-09-18 12:00:00    98\n","2017-09-18 13:00:00    95\n","2017-09-18 14:00:00    34\n","2017-09-18 15:00:00    47\n","2017-09-18 16:00:00    61\n","2017-09-18 17:00:00    70\n","Freq: H, dtype: int64\n","```\n","\n","#Upsampling Example\n","In the previous card, you have seen how to create a sample time series every 1 hour.\n","\n","If you want to study your data every 15 mins, you have to perform upsampling.\n","\n","How to perform upsampling?\n","\n","Observe the following usage.\n","```\n","sampleTs.resample('15min').head(10)\n","2017-09-18 08:00:00    62.0\n","2017-09-18 08:15:00     NaN\n","2017-09-18 08:30:00     NaN\n","2017-09-18 08:45:00     NaN\n","2017-09-18 09:00:00    22.0\n","2017-09-18 09:15:00     NaN\n","2017-09-18 09:30:00     NaN\n","2017-09-18 09:45:00     NaN\n","2017-09-18 10:00:00    22.0\n","2017-09-18 10:15:00     NaN\n","Freq: 15T, dtype: float64\n","```\n","If you have observed, the data shows time stamps at which the data was not captured as NaN.\n","\n","How to resolve this issue?\n","\n","#Forward Filling\n","The Forward and Backward filling can be used to fill missing values.\n","\n","In forward filling, you have to fill the missing values based on the forward values.\n","```\n","sampleTs.resample('15min', fill_method='ffill').head()\n","2017-09-18 08:00:00    62\n","2017-09-18 08:15:00    62\n","2017-09-18 08:30:00    62\n","2017-09-18 08:45:00    62\n","2017-09-18 09:00:00    22\n","Freq: 15T, dtype: int64\n","```\n","\n","#Backward Filling\n","In backward filling, the missing values are filled from backwards.\n","```\n","sampleTs.resample('15min', fill_method='bfill').head()\n","2017-09-18 08:00:00    62\n","2017-09-18 08:15:00    22\n","2017-09-18 08:30:00    22\n","2017-09-18 08:45:00    22\n","2017-09-18 09:00:00    22\n","Freq: 15T, dtype: int64\n","```\n","\n","#Fill with Limitation\n","When you fill the missing values, you can also limit the number of fills.\n","```\n","sampleTs.resample('15min', fill_method='ffill', limit=2).head()\n","2017-09-18 08:00:00    40.0\n","2017-09-18 08:15:00    40.0\n","2017-09-18 08:30:00    40.0\n","2017-09-18 08:45:00     NaN\n","2017-09-18 09:00:00    87.0\n","Freq: 15T, dtype: float64\n","```\n","You have noticed that the number of fills is limited to 2 in the above example. This can be any number.\n","\n","#Interpolation\n","Forward or Backward filling is a work around to fill the missing values.\n","\n","It might not be accurate.\n","\n","Some algorithms can fill the missing values based on the data patterns.\n","\n","This approach works better to get more accurate insights from Time Series Data.\n","\n","This method is called interpolation.\n","\n","You will now learn how to perform interpolation in Python.\n","\n","Interpolation Example\n","In the below example, you will see how to use interpolation to fix the missing values.\n","```\n","interEx = sampleTs.resample('15min')\n","interEx.head(10)\n","2017-09-18 08:00:00    40.0\n","2017-09-18 08:15:00     NaN\n","2017-09-18 08:30:00     NaN\n","2017-09-18 08:45:00     NaN\n","2017-09-18 09:00:00    87.0\n","2017-09-18 09:15:00     NaN\n","2017-09-18 09:30:00     NaN\n","2017-09-18 09:45:00     NaN\n","2017-09-18 10:00:00    51.0\n","2017-09-18 10:15:00     NaN\n","Freq: 15T, dtype: float64\n","interEx.interpolate().head(10)\n","2017-09-18 08:00:00    40.00\n","2017-09-18 08:15:00    51.75\n","2017-09-18 08:30:00    63.50\n","2017-09-18 08:45:00    75.25\n","2017-09-18 09:00:00    87.00\n","2017-09-18 09:15:00    78.00\n","2017-09-18 09:30:00    69.00\n","2017-09-18 09:45:00    60.00\n","2017-09-18 10:00:00    51.00\n","2017-09-18 10:15:00    57.25\n","Fre\n","q: 15T, dtype: float64\n","```"]},{"cell_type":"code","metadata":{"id":"e9g57VtroFTw","colab_type":"code","colab":{}},"source":["import pandas as pd\n","pd.date_range(start='2017-01-01',end='2017-01-19',freq='B')\n","pd.date_range(start=\"2017-01-01\", periods=5, freq='1D1h1T10s') == pd.date_range(start=\"2017-01-01\", periods=5, freq='1D1h1min10s')\n","pd.date_range(start=\"2017-01-01\", periods=5, freq='W-FRI')\n","\n","a = pd.date_range(start=\"2017-01-01\", periods=10, freq='BAS-JAN')\n","print(a)\n","b = pd.date_range(start=\"2017-01-01\", periods=10, freq='A-FEB')\n","print(b)\n","a.union(b)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UobD7WoOhXa0","colab_type":"code","colab":{}},"source":["import numpy as np\n","customerArrival = pd.date_range('18/09/2017 8:00', periods=600, freq='T')\n","custArrivalTs = pd.Series(np.random.randint(0, 100, len(customerArrival)), index=customerArrival)\n","custArrivalTs.head(10)\n","custArrivalTs.resample('M',how='max',)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTindRzCtS98","colab_type":"code","colab":{}},"source":["sampleRng = pd.date_range('2017-01-01', periods=6, freq='')\n","sampleTS = pd.Series(np.random.randint(0, 100, len(sampleRng)), index=sampleRng)\n","print(sampleTS)\n","\n","st = pd.DataFrame(sampleTs.resample('M',)).head()\n","print(st)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSohPqx9vXwn","colab_type":"code","colab":{}},"source":["###Start code here\n","upsample = closeTS.resample('M', how='max')\n","print(upsample)###End code(approx 1 line)\n","upsample.to_csv(\"output.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFuGPfOQGSip","colab_type":"text"},"source":["#List of Time Zones\n","List of Time Zones\n","There are many time zones in this world.\n","\n","One of the most used standard time zone is (coordinated universal time) UTC.\n","\n","All other time zones are expressed as offset of UTC. For example: US Eastern Time Zone is 4 hours behind UTC during Daylight saving and 5 hours behind rest of the year.\n","\n","#Time Zones in Python\n","To work with time zones, we can use pytz package in Python\n","```\n","import pytz \n","pytz.common_timezones[-5:]\n","['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']\n","```\n","In the example above, we have selected some common timezones.\n","\n","Time Zone Object\n","```\n","usEastTz = pytz.timezone('US/Eastern')\n","<DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD>\n","```\n","When you execute the above command, you will get the current time at the specified time zone.\n","\n","In the following cards, you will learn how to use timezone extensively.\n","\n","#Localization\n","Localization is the first step towards standardizing the time zone. Any specific time stamp is first localized to a given time zone.\n","You will now learn how to set your datetime index to a specific time zone.\n","\n","import pandas as pd \n","import random \n","timeZoneRng = pd.date_range('9/18/2017 9:30', periods=6, freq='D',tz='UTC')\n","timeZoneTs = pd.Series(np.random.randn(len(timeZoneRng)), index=timeZoneRng)\n","timeZoneTs.index.tz\n","<UTC> \n","In the example above, the given timezone is localized to UTC using the tz= parameter.\n","\n","You can also localize using the tz_localize() function.\n","\n","#Conversion\n","In the previous card, you have seen how to localize your date-time value to a particular time zone.\n","\n","If you want to convert your date-time value to another time zone you can use the tz_convert function.\n","```\n","timeZoneTs\n","2017-09-18 09:30:00+00:00   -1.825521\n","2017-09-19 09:30:00+00:00    0.961487\n","2017-09-20 09:30:00+00:00   -0.978146\n","2017-09-21 09:30:00+00:00    0.960428\n","2017-09-22 09:30:00+00:00   -0.077467\n","2017-09-23 09:30:00+00:00   -0.761420\n","Freq: D, dtype: float64\n","timeZoneTs.tz_convert('US/Eastern')\n","2017-09-18 05:30:00-04:00   -1.825521\n","2017-09-19 05:30:00-04:00    0.961487\n","2017-09-20 05:30:00-04:00   -0.978146\n","2017-09-21 05:30:00-04:00    0.960428\n","2017-09-22 05:30:00-04:00   -0.077467\n","2017-09-23 05:30:00-04:00   -0.761420\n","Freq: D, dtype: float64\n","```\n","\n","#Using Timestamp\n","You can create date values and convert them to different time zones and also perform similar operations with time stamp values.\n","\n","```\n","sampleTimeStamp =  pd.Timestamp('2011-09-19 04:00')\n","timeStamp_utc = sampleTimeStamp.tz_localize('UTC')\n","timeStamp_utc\n","Timestamp('2011-09-19 04:00:00+0000', tz='UTC')\n","timeStamp_utc.tz_convert('US/Eastern')\n","Timestamp('2011-09-19 00:00:00-0400', tz='US/Eastern')\n","```\n","The above example explains how to create a sample timestamp using TimeStamp function, Localize and Convert the timestamp to the desired value.\n","\n","\n","#Daylight Savings\n","Some timezones follow the daylight savings concept whereas some done.\n","\n","To offset the time based on Daylight Savings, you can use the DateOffset() function.\n","\n","The example below explains the steps.\n","```\n","# 30 minutes before DST transition\n","In [440]: from pandas.tseries.offsets import Hour\n","In [441]: stamp = pd.Timestamp('2012-03-12 01:30', tz='US/Eastern')\n","In [442]: stamp\n","Out[442]: <Timestamp: 2012-03-12 01:30:00-0400 EDT, tz=US/Eastern>\n","In [443]: stamp + Hour()\n","Out[443]: <Timestamp: 2012-03-12 02:30:00-0400 EDT, tz=US/Eastern>\n","# 90 minutes before DST transition\n","In [444]: stamp = pd.Timestamp('2012-11-04 00:30', tz='US/Eastern')\n","In [445]: stamp\n","Out[445]: <Timestamp: 2012-11-04 00:30:00-0400 EDT, tz=US/Eastern>\n","In [446]: stamp + 2 * Hour()\n","Out[446]: <Timestamp: 2012-11-04 01:30:00-0500 EST, tz=US/Eastern>\n","\n","```\n","\n","#Combining Different Timezones\n","When you work in a Multi National Company, you can get data from different time zone. But you have to bring them to one standard for working.\n","\n","In the below example, you will learn how to combine multiple timezones.\n","```\n","dateRng = pd.date_range('9/19/2017 9:30', periods=10, freq='B')\n","timeSeries =  pd.Series(np.random.randn(len(dateRng)), index=dateRng)\n","tz1 = timeSeries[:7].tz_localize('Asia/Singapore')\n","tz2 = tz1[2:].tz_convert('Asia/Seoul')\n","combine = tz1 + tz2\n","combine.index\n","DatetimeIndex(['2017-09-19 01:30:00+00:00', '2017-09-20 01:30:00+00:00',\n","               '2017-09-21 01:30:00+00:00', '2017-09-22 01:30:00+00:00',\n","               '2017-09-25 01:30:00+00:00', '2017-09-26 01:30:00+00:00',\n","               '2017-09-27 01:30:00+00:00'],\n","              dtype='datetime64[ns, UTC]', freq='B')\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"N71cbaCnHPbl","colab_type":"text"},"source":["#Plotting using Python\n","Plotting is easy with Python. You just have to pass the time series to the plot function.\n","```\n","%matplotlib inline \n","import pandas as pd\n","import numpy as np \n","sampleRng = pd.date_range(start='2017', periods=120, freq='MS')\n","sampleTs = pd.Series(np.random.randint(-10, 10, size=len(sampleRng)), sampleRng).cumsum()\n","sampleTs.head()\n","\n","sampleTs.plot(c='r', title='Sample time series')\n","```\n","In the above code, the time series is passed to the plot function. The necessary aesthetics like color, gridline, and scale can also be passed.\n","The above code creates a sample time series for plotting.\n","\n","#Lag Plot\n","The Lag Plot is a very important and useful visualization for Time Series Data.\n","\n","Time Series is a Univariate Data.\n","\n","In the lag plot, you plotted the actual data against the data with a time lag. This helps in determining how the current data is predicting the future data.\n","\n","#Lag Plot Using Python\n","Lag Plot Using Python\n","The below code explains how to create a sample lag plot in Python. You can use the time series created in the previous example.\n","```\n","from pandas.tools.plotting import lag_plot\n","lag_plot(sampleTs)\n","```\n","\n","#Auto Correlation Plot\n","In the lag plot, we have just seen how the data is scattered when plotted against one-time lag.\n","\n","Autocorrelation plot goes one step further.\n","\n","Auto Correlation refers to correlating the data with itself. Here we are correlating the data with a one-time lag.\n","\n","The plot gives a more accurate picture of how the data point is correlated among themselves.\n","\n","#Autocorrelation Plot in Python\n","Autocorrelation Plot in Python\n","from pandas.tools.plotting import autocorrelation_plot\n","autocorrelation_plot(sampleTs)\n","The plot drawn above shows the autocorrelation plot for the time series.\n","\n","When the autocorrelation plot shows an exponential behavior, the time series is stationary."]},{"cell_type":"code","metadata":{"id":"xW2nDBu9HcdM","colab_type":"code","colab":{}},"source":["sampleTs.resample('2A').plot(c='b', ls='--')\n","#In the above code, we have done a resampling of the time series annually and then plotted the values.\n","sampleTs.resample('5A').plot(c='g', ls='-.')\n","#In the above code, we have resampled further and then plot the values."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1fH_HdbHyYe","colab_type":"text"},"source":["#Stationarity\n","Stationarity is a very significant property in Time Series Analysis. In Time series, data is collected at different time intervals. The data might behave in a deterministic or stochastic nature.\n","\n","Models can be applied only when your data is deterministic. If the nature of the data is stochastic then the model results will not be interpretable. Hence we have to check this property before applying the model.\n","\n","#What is Stationarity?\n","In statistical terms, the mean, variance and the temporal correlation remain constant over time.\n","\n","A simpler definition is that there are no seasonal or trend components in the time series.\n","\n","#How to Check for Stationarity?\n","Data Visualization: You can look at your data and see if there are any trends or patterns. This is a very crude approach.\n","\n","Summary Statistics: You can take some summary statistics at different time intervals and see how the data behaves.\n","\n","Statistical Tests: You can apply certain specific statistical tests and check if your time series supports stationarity property.\n","\n","#Augmented Dickey - Fuller test\n","ADF test is the best way to determine if the time series data is stationary or not.\n","\n","This kind of test is known as Unit Root Test.\n","\n","The main objective of this test is that it identifies how the trend component determines the time series.\n","\n","#Statistics Behind ADF Test\n","ADF test makes use of an autoregressive model and optimizes its criteria across multiple lag values.\n","\n","The Null Hypothesis supposes that the time series is non-stationary.\n","\n","The alternate hypothesis is that the time series is stationary.\n","\n","#Interpreting the Results\n","Null Hypothesis: H0 - If accepted then the time series data is non-stationary, and it has a unit root.\n","\n","Alternate Hypothesis: H1 - The null hypothesis is rejected. The time series data is stationary and does not have any unit root.\n","\n","Results\n","\n","p-value > 0.05: Accept the (H0), the data is non-stationary and has a unit root.\n","\n","p-value <= 0.05: Reject the H0, the data is stationary and does not have a unit root.\n","\n","#Auto Correlation Function\n","Another way of determining stationarity is Autocorrelation Function. Here, you find the correlation between two data points that are one time step away.\n","\n","When you visualize this correlation, you can get insights on the stationarity of the time series.\n","\n","If the ACF plot is having an exponential decay, it means the time series is stationary.\n","\n","#Stationarity Check\n","In Python, the statsmodels package has a method named adffuller that can be used for stationarity check.\n","```\n","from statsmodels.tsa.stattools import adfuller\n","Once you pass your time series to this method, you will be able to get the results.\n","\n","The output has the following entities.\n","\n","ADF Statistic: \n","p-value: \n","\t1%: \n","\t5%: \n","\t10%:\n","\n","```\n","The more negative the ADF statistic value is the more likely the data is stationary.\n","\n","The ADF Statistic should be compared to critical p-values that are at 1, 5, and 10%.\n","\n","If the ADF statistic value is less than the critical value at 5% and the p-value is less than 0.05, then we can reject the null hypothesis that the data is non-stationary with 95% confidence level.\n","\n","#Sample Data Creation\n","Let us create a sample random time series.\n","```\n","import random \n","import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import adfuller\n","sampleRng = pd.date_range(start='2017', periods=120, freq='MS')\n","sampleTs = pd.Series(np.random.randint(-10, 10, size=len(sampleRng)), sampleRng).cumsum()\n","\n","tsResult = adfuller(sampleTs)\n","print('ADF Statistic: %f' % tsResult[0])\n","print('p-value: %f' % tsResult[1])\n","for key, value in tsResult[4].items():\n","    print('\\t%s: %.3f' % (key, value))\n","Output\n","\n","ADF Statistic: -1.328310\n","p-value: 0.616123\n","\t1%: -3.487\n","\t5%: -2.886\n","\t10%: -2.580\n","```\n","\n","Interpreting ADF Test Results\n","The ADF Statistic value is -1.328310. It is negative.\n","\n","The p-value: 0.616123 and is greater than 0.05 so we accept the null hypothesis, which means the data is non-stationary."]},{"cell_type":"markdown","metadata":{"id":"ypL3LZncTqaX","colab_type":"text"},"source":["#Components Explained\n","Trend: This component shows the overall series behavior - the slow change of values over time.\n","\n","Season: This shows the changes that happen in cycles that are less than one year.\n","\n","Cycles: Changes that happen for more than a year.\n","\n","Random: Anything that is not included in the above three components.\n","\n","The underlying assumption has to be that the time series data is stationary.\n","#Steps in Time Series Analysis\n","Few steps to be followed while performing time series analysis:\n","\n","Check for Stationarity.\n","\n","Decompose the model into its various components.\n","\n","Analyse the components.\n","\n","Fit the time series forecasting model and predict future values.\n","#Time Series Difference\n","Apart from the decomposing the Time Series, there is another method, you can follow while analysis is the difference.\n","\n","You take the difference between two time periods. The difference can have a shift of one time period or more.\n","\n","This process also helps in understanding the data better.\n","#Decomposing Using Python\n","Python used statsmodels package seasonal_decompose method for time series decomposing.\n","\n","You can just pass the time series and call the respective decomposing function to get the results.\n","#Seasonal Decomposition\n","```\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","sampleTs_decomp = seasonal_decompose(sampleTs, freq=12) \n","sampleTs_trend = sampleTs_decomp.trend \n","sampleTs_seasonal = sampleTs_decomp.seasonal \n","sampleTs_residual = sampleTs_decomp.resid\n","Here you can get the trend, seasonal, and residuals separately for the time series.\n","sampleTs_seasonal.plot()\n","```\n","#Modeling Time Series\n","So far, you have seen how to slice and dice the time series data and how to check for stationarity. The next logical step in time series analysis is forecasting. Forecasting in time series can be done in several ways.\n","\n","You will be learning about the following methodologies:\n","\n","Autoregressive\n","\n","Moving Average\n","\n","Autoregressive Moving Average\n","\n","Autoregressive Integrated Moving Average\n","\n","In Autoregression, you use the current value of the variable to predict its future values.\n","\n","Here, the current and past time stamp values of the time series are used to predict the future values.\n","\n","#Autoregression Using Python\n","```\n","from statsmodels.tsa.arima_model import ARIMA \n","model = ARIMA(ts, order=(1, 1, 0)) \n","predValues = model.fit()\n","```\n","The sample code above explains how Auto Regression is implemented in Python.\n","\n","The parameter order = is very important in calling the right function for forecasting.\n","\n","#What is Moving Average?\n","What is Moving Average?\n","Moving average is another way to predict the time series data.\n","\n","Here the dependent variable is expressed as a function of the previous values along with an average component.\n","\n","Average component keeps moving along the time series.\n","Moving Average Using Python\n","```\n","model = ARIMA(ts, order=(0, 1, 1)) \n","\n","movingAvgRes = model.fit() \n","```\n","ARIMA\n","ARIMA is the combination of Autoregressive and Moving Average.\n","\n","ARIMA stands for Autoregressive Integrated Moving Average.\n","\n","It is another model used for forecasting in Time Series Analysis.\n","\n","#Steps in Time Series\n","The first step is to visualize the time series.\n","\n","The second step is to make the data stationary.\n","\n"," - This can be accomplished by \n","\n"," - Detrending \n","\n"," - Differencing\n","\n"," - Seasonality \n","Getting the optimal parameters through Auto Correlation and Partial Auto Correlation\n","\n","Build Model (AR , MA , ARMA , ARIMA) using the parameters\n","\n","Make Predictions"]}]}